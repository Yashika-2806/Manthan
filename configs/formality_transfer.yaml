# Configuration for formality transfer

# Model settings
model:
  backbone: "facebook/bart-base"  # Can use bart-large, t5-base, etc.
  style_dim: 128
  num_styles: 4  # formal, informal, simple, complex
  hidden_dim: 768

# Data settings
data:
  train_path: "data/processed/gyafc_train.jsonl"
  val_path: "data/processed/gyafc_val.jsonl"
  test_path: "data/processed/gyafc_test.jsonl"
  max_length: 128
  extract_entities: true

# Training settings
training:
  batch_size: 32
  learning_rate: 3e-5
  weight_decay: 0.01
  epochs: 10
  warmup_steps: 1000
  num_workers: 4
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0

# Loss weights
losses:
  gen_weight: 1.0
  style_weight: 0.5
  contrastive_weight: 0.3
  entity_weight: 0.2
  cycle_weight: 0.1
  adversarial_weight: 0.1
  temperature: 0.07

# Seed for reproducibility
seed: 42

# Logging
logging:
  log_interval: 100
  eval_interval: 500
  save_interval: 1000
